{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a1396e-8f03-4148-99cc-5c6f2f0c7415",
   "metadata": {},
   "source": [
    "## Separating the Soups from the Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba48a812-b071-492a-b948-9a4e711d2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b76f3a1-6cac-400e-b31f-da39bf13c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_names_list = [\n",
    "    \"Lobster Bisque\",\n",
    "    \"Jambalaya\",\n",
    "    \"Shrimp Corn Chowder\",\n",
    "    \"New England Clam Chowder\",\n",
    "    \"Shrimp and Sausage Gumbo\",\n",
    "    \"Chicken Noodle\",\n",
    "    \"Chicken Dumpling\",\n",
    "    \"Chicken Corn Chowder\",\n",
    "    \"Buffalo Chicken\",\n",
    "    \"Chicken Tortilla\",\n",
    "    \"Chicken Enchilada\",\n",
    "    \"Chicken and Wild Rice\",\n",
    "    \"Chicken Barley\",\n",
    "    \"Chicken Orzo\",\n",
    "    \"Chicken Quinoa\",\n",
    "    \"Split Pea with Ham\",\n",
    "    \"Beef Chili\",\n",
    "    \"Potato Bacon\",\n",
    "    \"Chicken Chili\",\n",
    "    \"Chicken Lentil\",\n",
    "    \"Italian Wedding\",\n",
    "    \"Chicken Feta Cheese and Spinach\",\n",
    "    \"Sausage and Kale\",\n",
    "    \"Chicken Gumbo\",\n",
    "    \"Butternut Squash\",\n",
    "    \"Garden Vegetable\",\n",
    "    \"Tomato & Wild Rice\",\n",
    "    \"Lentil\",\n",
    "    \"Cuban Black Bean\",\n",
    "    \"Tomato Basil\",\n",
    "    \"Tomato Corn Chowder\",\n",
    "    \"Tomato Bisque\",\n",
    "    \"Tomato with Zucchini\",\n",
    "    \"Tomato Orzo\",\n",
    "    \"Broccoli and Cheese\",\n",
    "    \"Italian Ravioli\",\n",
    "    \"Minestrone\",\n",
    "    \"Potato Leek\",\n",
    "    \"Vegetarian Chili\",\n",
    "    \"Chicken Bone Broth\",\n",
    "    \"Lobster Roll\",\n",
    "    \"Mushroom Barley\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589435d3-7cf1-41b1-9f6a-cd32d2e609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the reviews as a dataframe\n",
    "reviews = pd.read_csv('soupman_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7091f22-adbe-4167-a68a-5166b59f4cf5",
   "metadata": {},
   "source": [
    "**Now it is time to see how effective the new model is at extracting the soup names from reviews, I will do this by creating a new column that holds the extracted soup names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8947928c-b0fd-411c-816b-f1cef9b35c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def create_soup_regex_patterns(soup_names_list):\n",
    "    # Escape special characters in soup names and join them into a single regex pattern\n",
    "    pattern = '|'.join(re.escape(name) for name in soup_names_list)\n",
    "    return re.compile(pattern, re.IGNORECASE)  # Compile regex pattern with case insensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23cdaca8-c423-4780-8a9e-b03cbe6274c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_soup_names_with_regex(text, soup_names_list):\n",
    "    soup_names_found = []\n",
    "    soup_name_dict = {soup.split(\" \")[0]: False for soup in soup_names_list}  # Create dictionary with soup names without \"soup\"\n",
    "    \n",
    "    # Check for each soup name in the text\n",
    "    for soup in soup_names_list:\n",
    "        # Create regex pattern for each soup name, considering potential punctuation\n",
    "        soup_regex = r\"\\b\" + re.escape(soup) + r\"\\b\"\n",
    "        # Search for soup name in text, ignoring case\n",
    "        if re.search(soup_regex, text, re.IGNORECASE):\n",
    "            soup_names_found.append(soup)\n",
    "            # Mark soup name as found in dictionary\n",
    "            soup_name_dict[soup.split(\" \")[0]] = True  \n",
    "    \n",
    "    # Check for soup names without \"soup\" in dictionary and add them if they haven't been found\n",
    "    for soup, found in soup_name_dict.items():\n",
    "        if not found:\n",
    "            soup_with_soup = soup + \" Soup\"\n",
    "            # Create regex pattern for each soup name with \"soup\", considering potential punctuation\n",
    "            soup_with_soup_regex = r\"\\b\" + re.escape(soup_with_soup) + r\"\\b\"\n",
    "            # Search for soup name with \"soup\" in text, ignoring case\n",
    "            if re.search(soup_with_soup_regex, text, re.IGNORECASE):\n",
    "                soup_names_found.append(soup_with_soup)\n",
    "\n",
    "    return soup_names_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e88bb5c-a240-48e9-be38-88779f3d57be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                   [Chicken Bone Broth]\n",
      "1                       [Chicken Dumpling, Lobster Roll]\n",
      "2                                      [Italian Wedding]\n",
      "3                     [Lobster Bisque, Chicken Tortilla]\n",
      "4      [Lobster Bisque, Chicken Dumpling, Chicken Tor...\n",
      "                             ...                        \n",
      "599                        [Chicken Gumbo, Lobster Roll]\n",
      "600                                         [Minestrone]\n",
      "601                                     [Lobster Bisque]\n",
      "602                                       [Lobster Soup]\n",
      "603                                     [Lobster Bisque]\n",
      "Name: soup_names_found, Length: 604, dtype: object\n"
     ]
    }
   ],
   "source": [
    "reviews['soup_names_found'] = reviews['review'].apply(lambda x: extract_soup_names_with_regex(x, soup_names_list))\n",
    "#pd.set_option('display.max_rows', None)\n",
    "print(reviews['soup_names_found'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd5a5a1-6aca-4038-9551-c9a3bc1c0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty lists: 143\n"
     ]
    }
   ],
   "source": [
    "empty_lists_count = sum(1 for soup_names in reviews['soup_names_found'] if not soup_names)\n",
    "print(\"Number of empty lists:\", empty_lists_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106c5f31-8c1c-456e-a38b-6af217ff819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-empty lists: 461\n"
     ]
    }
   ],
   "source": [
    "non_empty_lists_count = sum(1 for soup_names in reviews['soup_names_found'] if soup_names)\n",
    "print(\"Number of non-empty lists:\", non_empty_lists_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee5213fb-2b75-4de7-875a-39c22a462677",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"reviews_and_soups.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523c35d-ca48-4dc9-9854-37101cd7c8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
